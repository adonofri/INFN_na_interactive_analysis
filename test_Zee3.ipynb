{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44d603c-89e9-4b19-b000-d8a37cbb29c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/08\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import dask\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "from ROOT import RooRealVar, RooBreitWigner, RooCBShape, RooFFTConvPdf, RooChebychev, RooAddPdf, RooDataHist, RooPlot, TCanvas, TPad, TH1, TF1\n",
    "from ROOT import RooArgList\n",
    "import time\n",
    "# Initialize ROOT\n",
    "ROOT.PyConfig.IgnoreCommandLineOptions = True\n",
    "#ROOT.ROOT.EnableImplicitMT()\n",
    "from dask.distributed import LocalCluster, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84080ebd-433b-4cdc-af86-313fd4e62f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class variable(object):\n",
    "    def __init__(self, name, title, nbins=None, xmin=None, xmax=None):\n",
    "        self._name = name\n",
    "        self._title = title\n",
    "        self._nbins = nbins\n",
    "        self._xmin = xmin\n",
    "        self._xmax = xmax\n",
    "    def __str__(self):\n",
    "        return  '\\\"'+str(self._name)+'\\\",\\\"'+str(self._title)+'\\\",\\\"'+str(self._nbins)+','+str(self._xmin)+','+str(self._xmax)\n",
    "\n",
    "my_vars = []\n",
    "\n",
    "my_vars.append(variable(name = \"e1_energy\", title= \"leading electron energy [GeV]\", nbins = 50, xmin = 0, xmax=100))\n",
    "my_vars.append(variable(name = \"e2_energy\", title= \"sub leading electron energy [GeV]\", nbins = 50, xmin = 0, xmax=100))\n",
    "my_vars.append(variable(name = \"m_ee\", title= \"Zee invariant mass, m_{ee} [GeV]\", nbins = 50, xmin = 84, xmax=98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38bc5f98-1fe8-4367-b7fe-bd13c9d7ba6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: events Title: Events tree\n",
      "Name: metadata Title: Metadata tree\n",
      "Name: run_metadata Title: Run metadata tree\n",
      "Name: evt_metadata Title: Event metadata tree\n",
      "Name: col_metadata Title: Collection metadata tree\n"
     ]
    }
   ],
   "source": [
    "#global variables                                                                                                                                                \n",
    "fit_lowcut = 84.\n",
    "fit_highcut = 98.\n",
    "NbinsX = 50\n",
    "\n",
    "nmaxiteration = 1\n",
    "recreate_files= True\n",
    "\n",
    "nmaxpartition = 1\n",
    "distributed = True\n",
    "\n",
    "\n",
    "file = ROOT.TFile.Open(\"/home/jovyan/work/RDataFrame_test/ee_Z_ee_EDM4Hep.root\")\n",
    "#file = ROOT.TFile.Open(\"/home/jovyan/work/RDataFrame_test/input_times_200.root\")\n",
    "\n",
    "for a in file.GetListOfKeys():\n",
    "    print(a)\n",
    "    \n",
    "folder = \"/home/jovyan/work/RDataFrame_test/output/mytest_Zee/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "repohisto = folder+\"plots/\"\n",
    "if not os.path.exists(repohisto):\n",
    "    os.mkdir(repohisto)    \n",
    "    \n",
    "text_file = open(\"/home/jovyan/work/RDataFrame_test/utils/functions.h\", \"r\")   \n",
    "data = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13425ccb-6fc4-4450-b9b4-d0944ce8e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_initialization_function():\n",
    "    print(ROOT.gInterpreter.ProcessLine(\".O\"))\n",
    "    ROOT.gInterpreter.Declare('{}'.format(data))\n",
    "    print(\"end of initialization\")\n",
    "    \n",
    "def create_connection():\n",
    "    \"\"\"\n",
    "    Setup connection to a Dask cluster. Two ingredients are needed:\n",
    "    1. Creating a cluster object that represents computing resources. This can be\n",
    "       done in various ways depending on the type of resources at disposal. To use\n",
    "       only the local machine (e.g. your laptop), a `LocalCluster` object can be\n",
    "       used. This step can be skipped if you have access to an existing Dask\n",
    "       cluster; in that case, the cluster administrator should provide you with a\n",
    "       URL to connect to the cluster in step 2. More options for cluster creation\n",
    "       can be found in the Dask docs at\n",
    "       http://distributed.dask.org/en/stable/api.html#cluster .\n",
    "    2. Creating a Dask client object that connects to the cluster. This accepts\n",
    "       directly the object previously created. In case the cluster was setup\n",
    "       externally, you need to provide an endpoint URL to the client, e.g.\n",
    "       'https://myscheduler.domain:8786'.\n",
    " \n",
    "    Through Dask, you can connect to various types of cluster resources. For\n",
    "    example, you can connect together a set of machines through SSH and use them\n",
    "    to run your computations. This is done through the `SSHCluster` class. For\n",
    "    example:\n",
    " \n",
    "    ```python\n",
    "    from dask.distributed import SSHCluster\n",
    "    cluster = SSHCluster(\n",
    "        # A list with machine host names, the first name will be used as\n",
    "        # scheduler, following names will become workers.\n",
    "        hosts=[\"machine1\",\"machine2\",\"machine3\"],\n",
    "        # A dictionary of options for each worker node, here we set the number\n",
    "        # of cores to be used on each node.\n",
    "        worker_options={\"nprocs\":4,},\n",
    "    )\n",
    "    ```\n",
    " \n",
    "    Another common usecase is interfacing Dask to a batch system like HTCondor or\n",
    "    Slurm. A separate package called dask-jobqueue (https://jobqueue.dask.org)\n",
    "    extends the available Dask cluster classes to enable running Dask computations\n",
    "    as batch jobs. In this case, the cluster object usually receives the parameters\n",
    "    that would be written in the job description file. For example:\n",
    " \n",
    "    ```python\n",
    "    from dask_jobqueue import HTCondorCluster\n",
    "    cluster = HTCondorCluster(\n",
    "        cores=1,\n",
    "        memory='2000MB',\n",
    "        disk='1000MB',\n",
    "    )\n",
    "    # Use the scale method to send as many jobs as needed\n",
    "    cluster.scale(4)\n",
    "    ```\n",
    " \n",
    "    In this tutorial, a cluster object is created for the local machine, using\n",
    "    multiprocessing (processes=True) on 4 workers (n_workers=4) each using only\n",
    "    1 core (threads_per_worker=1).\n",
    "    \"\"\"\n",
    "    cluster = LocalCluster(n_workers=2, threads_per_worker=1, processes=True)\n",
    "    client = Client(cluster)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcfc7954-8674-41d9-9cb6-399a6f5a8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGetFitParameters(map_histog, mean_bw, input_width, input_sigma, path, m_sf, NbinsX, fit_lowcut, fit_highcut):\n",
    "    parameters = []\n",
    "\n",
    "    x = RooRealVar(\"x\", \"x\", fit_lowcut, fit_highcut)  # 84,98//80-100                                                                                           \n",
    "    x.setBins(10000, \"cache\")\n",
    "    x.setMin(\"cache\", 64.)\n",
    "    x.setMax(\"cache\", 118.)\n",
    "\n",
    "    m0 = RooRealVar(\"m0\", \"m0\", mean_bw, fit_lowcut, fit_highcut)  # 80-100                                                                                      \n",
    "    width = RooRealVar(\"width\", \"width\", input_width, 1., 4.)\n",
    "    bw = RooBreitWigner(\"bw\", \"bw\", x, m0, width)\n",
    "\n",
    "    mean = RooRealVar(\"mean\", \"mean\", 0.)\n",
    "    sigma = RooRealVar(\"sigma\", \"sigma\", input_sigma, 1., 5.)\n",
    "    alpha = RooRealVar(\"alpha\", \"alpha\", 1.3)\n",
    "    n = RooRealVar(\"n\", \"n\", 5.1)\n",
    "    cb = RooCBShape(\"cb\", \"cb\", x, mean, sigma, alpha, n)\n",
    "\n",
    "    pdf_sig = RooFFTConvPdf(\"pdf_sig\", \"pdf_sig\", x, bw, cb)\n",
    "    coef0 = RooRealVar(\"c0\", \"coefficient #0\", 1.0, -.01, 0.01)\n",
    "    coef1 = RooRealVar(\"c1\", \"coefficient #1\", -0.1, -.01, 0.01)\n",
    "    coef2 = RooRealVar(\"c2\", \"coefficient #2\", -0.1, -.01, 0.01)\n",
    "    bkg1 = RooChebychev(\"bkg1\", \"bkg1\", x, RooArgList(coef0, coef1, coef2))\n",
    "    fsig = RooRealVar(\"fsig\", \"signal fraction\", 0.9, 0., 1.)\n",
    "    pdf = RooAddPdf(\"pdf\", \"pdf\", RooArgList(pdf_sig, bkg1), RooArgList(fsig))\n",
    "    histo = RooDataHist(\"histo\", \"histo\", x, Import=map_histog)\n",
    "    x.setRange(\"signal\", fit_lowcut, fit_highcut)\n",
    "\n",
    "    ROOT.Math.MinimizerOptions.SetDefaultMinimizer(\"Minuit2\")\n",
    "    ROOT.Math.MinimizerOptions.SetDefaultTolerance(0.0000001)\n",
    "    ROOT.Math.MinimizerOptions.SetDefaultPrecision(0.0000001)\n",
    "\n",
    "    pdf.fitTo(histo, SumW2Error=True, Range=\"signal\")\n",
    "\n",
    "    canv = ROOT.TCanvas(\"canv\", \"canv\", 800, 600)\n",
    "    frame1 = x.frame(Bins=NbinsX, Title=\"Convolution of a Breit-Wigner and a Crystal-Ball, Chebychev pol. bkg\")\n",
    "    histo.plotOn(frame1, Name=\"Data\")\n",
    "    pdf.plotOn(frame1, Name=\"pdf\", LineColor=ROOT.kRed)\n",
    "    pdf.paramOn(frame1, Layout=0.60)\n",
    "    pdf.plotOn(frame1, Components=\"bkg1\", LineStyle=ROOT.kDotted, LineColor=ROOT.kBlue)\n",
    "\n",
    "    canvas = TCanvas(\"canvas\", \"canvas\", 800, 600)\n",
    "    canvas.cd()\n",
    "    pad1 = TPad(\"pad1\", \"pad1name\", 0.01, 0.31, 0.99, 0.99)\n",
    "    pad2 = TPad(\"pad2\", \"pad2name\", 0.01, 0.01, 0.99, 0.41)\n",
    "    pad1.Draw()\n",
    "    pad2.Draw()\n",
    "    pad1.cd()\n",
    "    pad1.SetBottomMargin(0.16)\n",
    "    pad2.SetBottomMargin(0.24)\n",
    "    frame1.GetYaxis().SetTitleOffset(1.4)\n",
    "    frame1.GetXaxis().SetTitle(\"m_ee [GeV], sf_\"+str(i_sf))\n",
    "    frame1.Draw()\n",
    "    pad1.Modified()\n",
    "    pad1.RedrawAxis()\n",
    "    pad1.Update()\n",
    "    pad2.cd()\n",
    "\n",
    "    tf1_model = pdf.asTF(x)\n",
    "    clone_data = histo.createHistogram(\"clone_data\",x,Binning=(NbinsX,fit_lowcut,fit_highcut))\n",
    "    pdfHisto_data = pdf.generateBinned({x}, 1000000)\n",
    "    clone_fit_data = pdfHisto_data.createHistogram(\"clone_fit_data\",x,Binning=(NbinsX,fit_lowcut,fit_highcut))\n",
    "    clone_fit_data.Scale(clone_data.Integral()/clone_fit_data.Integral())\n",
    "\n",
    "    pdfHisto = pdf_sig.generateBinned({x}, 1000000)\n",
    "    clone_fit = pdfHisto.createHistogram(\"clone_fit\",x,Binning=(NbinsX,fit_lowcut,fit_highcut))\n",
    "    clone_fit.Scale(clone_data.Integral()/clone_fit.Integral())\n",
    "    \n",
    "    x1 = fit_lowcut\n",
    "    x2 = fit_highcut\n",
    "    bin1 = clone_data.FindBin(x1)\n",
    "    bin2 = clone_data.FindBin(x2)\n",
    "\n",
    "    for i in range(0,clone_data.GetNbinsX() + 1):\n",
    "        if i < bin1:\n",
    "            clone_data.SetBinContent(i, 0.)\n",
    "        if i > bin2:\n",
    "            clone_data.SetBinContent(i, 0.)\n",
    "\n",
    "\n",
    "    clone_data.Divide(clone_fit_data)\n",
    "\n",
    "    clone_data.GetXaxis().SetTitle(\"m_ee [GeV], sf_\"+str(i_sf))\n",
    "    clone_data.GetYaxis().SetTitle(\"DATA / FIT\")\n",
    "    clone_data.GetXaxis().SetRangeUser(fit_lowcut, fit_highcut)\n",
    "    clone_data.GetYaxis().SetRangeUser(0., 2.)\n",
    "    clone_data.GetXaxis().SetLabelSize(0.1)\n",
    "    clone_data.GetYaxis().SetLabelSize(0.08)\n",
    "    clone_data.GetXaxis().SetTitleSize(0.08)\n",
    "    clone_data.GetYaxis().SetTitleSize(0.09)\n",
    "    clone_data.GetYaxis().SetTitleOffset(0.6)\n",
    "    clone_data.GetXaxis().SetTitleOffset(1.2)\n",
    "    clone_data.Draw(\"E1\")\n",
    "    pad2.Modified()\n",
    "    pad2.SetGridy()\n",
    "    pad2.RedrawAxis()\n",
    "    pad2.Update()\n",
    "\n",
    "    output_folder = path + \"FitPlots\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    canvas.SaveAs(path + \"FitPlots/sf_\"+str(i_sf)+\".pdf\")\n",
    "    canvas.SaveAs(path + \"FitPlots/sf_\"+str(i_sf)+\".root\")\n",
    "\n",
    "    modelMean = tf1_model.GetMaximumX()\n",
    "\n",
    "    parameters.append(modelMean)  # 0                                                                                                                            \n",
    "    parameters.append(m0.getError())  # 1                                                                                                                        \n",
    "    parameters.append(m0.getVal())  # 2                                                                                                                          \n",
    "    parameters.append(sigma.getVal())  # 3  \n",
    "    parameters.append(sigma.getError())  # 4                                                                                                                     \n",
    "    parameters.append(mean.getVal())  # 5                                                                                                                        \n",
    "    parameters.append(mean.getError())  # 6                                                                                                                      \n",
    "    parameters.append(alpha.getVal())  # 7                                                                                                                       \n",
    "    parameters.append(alpha.getError())  # 8                                                                                                                     \n",
    "    parameters.append(n.getVal())  # 9                                                                                                                           \n",
    "    parameters.append(n.getError())  # 10                                                                                                                        \n",
    "    parameters.append(width.getVal())  # 11                                                                                                                      \n",
    "    parameters.append(width.getError())  # 12                                                                                                                    \n",
    "\n",
    "    #print(\"width =\", width.getVal())\n",
    "\n",
    "    # Elimina gli oggetti                                                                                                                                        \n",
    "    del frame1\n",
    "    del clone_data\n",
    "    del clone_fit\n",
    "    del pad1\n",
    "    del pad2\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ace543df-a250-411d-8bec-22e01a252bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookhisto(df, var, nmaxiteration):\n",
    "    h_ = {}\n",
    "    \n",
    "    for i_sf in range(0,nmaxiteration):\n",
    "        i_sf = str(i_sf)\n",
    "        h_[i_sf] = {}\n",
    "        for v in var:           \n",
    "            h_[i_sf][v._name+\"_\"+str(i_sf)]= df.Histo1D(ROOT.RDF.TH1DModel(v._name+\"_\"+str(i_sf), v._title+\"; Events\", v._nbins, v._xmin, v._xmax), v._name+\"_\"+str(i_sf))\n",
    "            print(v._name+\"_\"+str(i_sf))\n",
    "            #h_[i_sf][v._name].GetValue()\n",
    "        \n",
    "    print(\"Done bookhisto!\")\n",
    "    return h_    \n",
    "\n",
    "\n",
    "def savehisto(h, var, nmaxiteration, repohisto):\n",
    "\n",
    "    for i_sf in range(0,nmaxiteration):\n",
    "        i_sf = str(i_sf)\n",
    "        for v in var:\n",
    "            histo = ROOT.TH1D(v._name+\"_\"+str(i_sf),v._title+\"; Events\", v._nbins, v._xmin, v._xmax)\n",
    "            \n",
    "    \n",
    "    label=\"m_ee_test\"\n",
    "    \n",
    "    Z_resolution = []\n",
    "    \n",
    "    if recreate_files== True:\n",
    "        outfile = ROOT.TFile.Open(repohisto+label+'.root', \"RECREATE\")\n",
    "    else:\n",
    "        outfile = ROOT.TFile.Open(repohisto+label+'.root', \"Update\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    for i_sf in range(0,nmaxiteration):\n",
    "        i_sf = str(i_sf)\n",
    "        #h[i_sf] = {}\n",
    "        for v in var:\n",
    "            print(h[i_sf].keys())\n",
    "            tmp = h[i_sf][v._name+\"_\"+str(i_sf)].GetValue()\n",
    "            outfile.cd()\n",
    "            histo.Write()\n",
    "            tmp.Sumw2()\n",
    "            if v._name == \"Z_ee\":\n",
    "                #Z_resolution.append(myGetFitParameters(m_histo_Mee, m_histo_Mee.GetMean(),width_mass_mc, sigma_mass_mc, folder, i_sf, NbinsX, fit_lowcut, fit_highcut)[3])\n",
    "                Z_resolution.append(tmp.GetMean())\n",
    "    \n",
    "    outfile.Close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cdeab5c-f91c-4cd2-812c-3c40a4cfc280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "end of initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/distributed/node.py:183: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 45393 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1_energy\n",
      "e2_energy\n",
      "m_ee\n",
      "e1_energy_0\n",
      "e2_energy_0\n",
      "m_ee_0\n",
      "Done bookhisto!\n",
      "dict_keys(['e1_energy_0', 'e2_energy_0', 'm_ee_0'])\n",
      "dict_keys(['e1_energy_0', 'e2_energy_0', 'm_ee_0'])\n",
      "dict_keys(['e1_energy_0', 'e2_energy_0', 'm_ee_0'])\n",
      "Tempo impiegato in secondi:  369.7502746582031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "input_line_146:56:7: error: redefinition of 'ComputeInvariantMass'\n",
      "float ComputeInvariantMass(Vec_t px, Vec_t py, Vec_t pz, Vec_t e) {                                                                                              \n",
      "      ^\n",
      "input_line_106:56:7: note: previous definition is here\n",
      "float ComputeInvariantMass(Vec_t px, Vec_t py, Vec_t pz, Vec_t e) {                                                                                              \n",
      "      ^\n",
      "input_line_146:63:7: error: redefinition of 'ComputeEnergy'\n",
      "RVecF ComputeEnergy(Vec_t px, Vec_t py, Vec_t pz, double m_e) {                                                                                                  \n",
      "      ^\n",
      "input_line_106:63:7: note: previous definition is here\n",
      "RVecF ComputeEnergy(Vec_t px, Vec_t py, Vec_t pz, double m_e) {                                                                                                  \n",
      "      ^\n",
      "input_line_146:74:21: error: redefinition of 'myGetFitParameters'\n",
      "std::vector<double> myGetFitParameters(TH1D map_histog, double mean_bw, double input_width, double input_sigma, TString path, int m_sf){\n",
      "                    ^\n",
      "input_line_106:74:21: note: previous definition is here\n",
      "std::vector<double> myGetFitParameters(TH1D map_histog, double mean_bw, double input_width, double input_sigma, TString path, int m_sf){\n",
      "                    ^\n",
      "Warning in <TClass::Init>: no dictionary for class podio::GenericParameters is available\n",
      "Warning in <TClass::Init>: no dictionary for class podio::ObjectID is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::ClusterData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::Vector3f is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::MCParticleData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::Vector3d is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::Vector2i is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::ReconstructedParticleData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::MCRecoParticleAssociationData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::ParticleIDData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::TrackData is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::TrackState is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm4hep::RecoParticleRefData is available\n",
      "Warning in <TClass::Init>: no dictionary for class podio::CollectionIDTable is available\n",
      "Warning in <TClass::Init>: no dictionary for class pair<int,podio::GenericParameters> is available\n"
     ]
    }
   ],
   "source": [
    "#MAIN                                                                                                                                                            \n",
    "\n",
    "# set up everything properly\n",
    "if distributed == True:\n",
    "    RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame\n",
    "    ROOT.RDF.Experimental.Distributed.initialize(my_initialization_function)\n",
    "else:\n",
    "    RDataFrame = ROOT.RDataFrame\n",
    "    my_initialization_function()\n",
    "\n",
    "\n",
    "# Create an RDataFrame that will use Dask as a backend for computations\n",
    "if distributed ==True:\n",
    "    connection = create_connection()\n",
    "    df = RDataFrame(\"events\", file, npartitions=nmaxpartition, \n",
    "                            daskclient=connection)\n",
    "else:\n",
    "    df = RDataFrame(\"events\", file)\n",
    "\n",
    "\n",
    "var = my_vars\n",
    "\n",
    "for v in var:\n",
    "    print(v._name)\n",
    "\n",
    "df = df.Define('w_nominal', '1')\n",
    "df = df.Define(\"m_e\",\"0.0005124\") #GeV                                                                                                                           \n",
    "df_ge = df.Define(\"goodelectrons\", \"Particle.charge[0]*Particle.charge[1] < 0.\").Filter(\"goodelectrons > 0\")\n",
    "\n",
    "\n",
    "# Inizia a misurare il tempo\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "width_mass_mc = 2.49 #GeV                                                                                                                                        \n",
    "sigma_mass_mc = 2.6 #GeV                                                                                                                                         \n",
    "\n",
    "\n",
    "for i_sf in range(0,nmaxiteration):\n",
    "\n",
    "    df_Mee = df_ge.Define(\"m_ee_\"+str(i_sf), \"ComputeInvariantMass(Particle.momentum.x, Particle.momentum.y, Particle.momentum.z, ComputeEnergy(Particle.momentum.x, Partic\\\n",
    "le.momentum.y, Particle.momentum.z,m_e))\")\n",
    "\n",
    "    '''                                                                                                                                                          \n",
    "    che pesi usare?                                                                                                                                              \n",
    "    df = df.Define(\"w_nominal\",\"scaleFactor_ELECTRON * scaleFactor_ElectronTRIGGER * scaleFactor_PILEUP * mcWeight\");                                               \n",
    "    '''\n",
    "\n",
    "    df_Mee = df_Mee.Define(\"e1_energy_\"+str(i_sf),\"ComputeEnergy(Particle.momentum.x, Particle.momentum.y, Particle.momentum.z,m_e)[0]\")\n",
    "    df_Mee = df_Mee.Define(\"e2_energy_\"+str(i_sf),\"ComputeEnergy(Particle.momentum.x, Particle.momentum.y, Particle.momentum.z,m_e)[1]\")\n",
    "\n",
    "    \n",
    "    \n",
    "tmp=bookhisto(df_Mee, var, nmaxiteration)\n",
    "savehisto(tmp, var, nmaxiteration, repohisto)\n",
    "\n",
    "\n",
    "# Termina la misurazione del tempo\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcola il tempo trascorso\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Stampa il risultato\n",
    "print(\"Tempo impiegato in secondi: \", elapsed_time)    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02b3f9-b595-495c-856f-7b5f42d9d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848668a-8556-4e6c-a94f-131336de66b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
